---
// TypeScript support enabled
---
<html lang="en">
	<head>
		<meta charset="UTF-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0" />
		<title>Video Wallpaper Generator</title>
		<style>
			@keyframes spin {
				0% { transform: rotate(0deg); }
				100% { transform: rotate(360deg); }
			}
		</style>
	</head>
	<body style="font-family: system-ui, sans-serif; background: #18181b; color: #fff; margin: 0;">
		<main style="max-width: 800px; margin: 3rem auto; padding: 2rem; background: #23232a; border-radius: 1rem; box-shadow: 0 2px 16px #0002;">
			<h1 style="font-size: 2.5rem; margin-bottom: 0.5em;">Video Wallpaper Generator</h1>
			<p style="font-size: 1.2rem; margin-bottom: 2em;">
				Transform your podcast or radio show audio into YouTube-ready video with evolving, ambient visuals and automated branding overlays.
			</p>
			
			<div id="workflow" style="margin-bottom: 2em;">
				<h3>Workflow:</h3>
				<ol>
					<li>Upload your audio file (WAV/MP3, â‰¤ 250 MB)</li>
					<li>Enter episode details (optional)</li>
					<li>Select a visual style preset</li>
					<li>Preview a 15-second sample</li>
					<li>Approve or regenerate</li>
					<li>Render and download your full video</li>
				</ol>
			</div>

			<div style="margin-bottom: 2em; padding: 1.5em; background: #1f1f23; border-radius: 0.5em; border: 1px solid #333;">
				<h3 style="margin-top: 0; color: #6366f1;">Quick Test Videos</h3>
				<p style="margin-bottom: 1em; color: #aaa;">
					Generate sample videos with different style presets to test the system.
				</p>
				<div style="display: flex; flex-wrap: wrap; gap: 1em; margin-bottom: 1em;">
					<button 
						id="testVideoFrenchNewWave"
						style="padding: 0.75em 1.5em; font-size: 1em; background: #6366f1; color: #fff; border: none; border-radius: 0.5em; cursor: pointer;"
					>
						ðŸŽ¬ French New Wave
					</button>
					<button 
						id="testVideoRetro"
						style="padding: 0.75em 1.5em; font-size: 1em; background: #8b5cf6; color: #fff; border: none; border-radius: 0.5em; cursor: pointer;"
					>
						ðŸŽ¬ '80s Retro Chromatic
					</button>
					<button 
						id="testVideoWineCountry"
						style="padding: 0.75em 1.5em; font-size: 1em; background: #d97706; color: #fff; border: none; border-radius: 0.5em; cursor: pointer;"
					>
						ðŸŽ¬ Wine-Country Dreamscape
					</button>
				</div>
				<span style="color: #aaa; font-size: 0.9em;">Each creates a 5-second sample with the selected style preset</span>
			</div>

			<!-- Live Preview Canvas -->
			<div id="livePreviewContainer" style="margin-bottom: 2em; background: #1f1f23; border-radius: 0.5em; overflow: hidden; border: 1px solid #333; display: none;">
				<div style="padding: 1em; text-align: center; color: #6366f1; font-weight: 500; border-bottom: 1px solid #333;">
					ðŸŽ¬ Live Preview
				</div>
				<canvas 
					id="livePreviewCanvas" 
					style="width: 100%; max-width: 100%; height: auto; display: block; background: #000;"
				></canvas>
			</div>

			<!-- Processing Status -->
			<div id="status" style="margin-bottom: 2em; display: none;">
				<h3>Processing Status:</h3>
				<div id="statusText" style="color: #10b981; font-weight: 500; margin-bottom: 0.5em;"></div>
				<div id="stageIndicator" style="color: #6366f1; font-size: 0.9em; margin-bottom: 1em;"></div>
				
				<div id="progress" style="margin-top: 1em;">
					<div style="background: #1f1f23; height: 20px; border-radius: 10px; overflow: hidden; position: relative;">
						<div id="progressBar" style="width: 0%; height: 100%; background: linear-gradient(90deg, #6366f1, #8b5cf6); border-radius: 10px; transition: width 0.5s ease; position: relative;">
							<div style="position: absolute; right: 8px; top: 50%; transform: translateY(-50%); color: white; font-size: 0.8em; font-weight: 500; text-shadow: 0 1px 2px rgba(0,0,0,0.5);"></div>
						</div>
					</div>
				</div>
				<div id="frameCountIndicator" style="margin-top: 0.5em; color: #aaa; font-size: 0.9em;"></div>
			</div>

			<form id="uploadForm" style="display: flex; flex-direction: column; gap: 1.5em;">
				<div>
					<label for="audioFile">
						<strong>Audio File</strong>
					</label>
					<input 
						type="file" 
						id="audioFile" 
						name="audio" 
						accept="audio/wav,audio/mp3" 
						style="margin-top: 0.5em; width: 100%;" 
						required
					/>
					<div id="fileInfo" style="margin-top: 0.5em; font-size: 0.9em; color: #aaa;"></div>
				</div>

				<div>
					<label for="title">
						<strong>Episode Title</strong>
					</label>
					<input 
						type="text" 
						id="title" 
						name="title" 
						placeholder="Enter episode title" 
						style="margin-top: 0.5em; width: 100%; padding: 0.5em;" 
					/>
				</div>

				<div>
					<label for="guest">
						<strong>Guest (Optional)</strong>
					</label>
					<input 
						type="text" 
						id="guest" 
						name="guest" 
						placeholder="Guest name" 
						style="margin-top: 0.5em; width: 100%; padding: 0.5em;" 
					/>
				</div>

				<div>
					<label for="sponsor">
						<strong>Sponsor (Optional)</strong>
					</label>
					<input 
						type="text" 
						id="sponsor" 
						name="sponsor" 
						placeholder="Sponsor name" 
						style="margin-top: 0.5em; width: 100%; padding: 0.5em;" 
					/>
				</div>

				<div>
					<label for="stylePreset">
						<strong>Style Preset</strong>
					</label>
					<select 
						id="stylePreset" 
						name="stylePreset" 
						style="margin-top: 0.5em; width: 100%; padding: 0.5em;"
					>
						<option value="French New Wave">French New Wave</option>
						<option value="'80s Retro Chromatic">'80s Retro Chromatic</option>
						<option value="Wine-Country Dreamscape">Wine-Country Dreamscape</option>
					</select>
				</div>

				<button 
					type="submit" 
					id="submitBtn"
					style="padding: 0.75em 2em; font-size: 1.1em; background: #6366f1; color: #fff; border: none; border-radius: 0.5em; cursor: pointer;"
				>
					Generate Video
				</button>
			</form>

			<div id="results" style="margin-top: 2em; display: none;">
				<h3>Results:</h3>
				<div id="videoInfo" style="background: #1f1f23; padding: 1em; border-radius: 0.5em; margin-bottom: 1em;"></div>
				
				<!-- Video Player -->
				<div id="videoPlayerContainer" style="margin-bottom: 1em; background: #1f1f23; border-radius: 0.5em; overflow: hidden; border: 1px solid #333;">
					<div id="videoLoadingIndicator" style="display: none; text-align: center; padding: 2em; color: #6366f1;">
						<div style="margin-bottom: 1em;">ðŸŽ¬ Loading video...</div>
						<div style="width: 40px; height: 40px; border: 3px solid #333; border-top: 3px solid #6366f1; border-radius: 50%; animation: spin 1s linear infinite; margin: 0 auto;"></div>
					</div>
					<video 
						id="videoPlayer" 
						controls 
						style="width: 100%; max-width: 100%; height: auto; display: block; background: #000;"
						preload="metadata"
					>
						Your browser does not support the video tag.
					</video>
				</div>
				
				<div style="display: flex; gap: 1em;">
					<button id="downloadBtn" style="padding: 0.5em 1em; background: #10b981; color: #fff; border: none; border-radius: 0.5em; cursor: pointer;">
						Download Video
					</button>
					<button id="youtubeBtn" style="padding: 0.5em 1em; background: #ef4444; color: #fff; border: none; border-radius: 0.5em; cursor: pointer;">
						Upload to YouTube
					</button>
				</div>
			</div>

			<div style="margin-top: 2em; color: #aaa; font-size: 0.95em;">
				<p><em>Note: This is an MVP prototype. Video rendering and AI visuals are simulated for demonstration.</em></p>
			</div>
		</main>

		<script>
			console.log('SCRIPT LOADED');
			const form = document.getElementById('uploadForm') as HTMLFormElement;
			const fileInput = document.getElementById('audioFile') as HTMLInputElement;
			const fileInfo = document.getElementById('fileInfo') as HTMLDivElement;
			const status = document.getElementById('status') as HTMLDivElement;
			const statusText = document.getElementById('statusText') as HTMLDivElement;
			const stageIndicator = document.getElementById('stageIndicator') as HTMLDivElement;
			const progressBar = document.getElementById('progressBar') as HTMLDivElement;
			const results = document.getElementById('results') as HTMLDivElement;
			const videoInfo = document.getElementById('videoInfo') as HTMLDivElement;
			const downloadBtn = document.getElementById('downloadBtn') as HTMLButtonElement;
			const youtubeBtn = document.getElementById('youtubeBtn') as HTMLButtonElement;
			const frameCountIndicator = document.getElementById('frameCountIndicator') as HTMLDivElement;
			const testVideoFrenchNewWave = document.getElementById('testVideoFrenchNewWave') as HTMLButtonElement;
			const testVideoRetro = document.getElementById('testVideoRetro') as HTMLButtonElement;
			const testVideoWineCountry = document.getElementById('testVideoWineCountry') as HTMLButtonElement;
			const videoPlayer = document.getElementById('videoPlayer') as HTMLVideoElement;
			const videoLoadingIndicator = document.getElementById('videoLoadingIndicator') as HTMLDivElement;
			const livePreviewCanvas = document.getElementById('livePreviewCanvas') as HTMLCanvasElement;
			const livePreviewContainer = document.getElementById('livePreviewContainer') as HTMLDivElement;

			let currentVideoPath: string = '';
			let currentVideoUrl: string = '';
			let currentJobId: string = '';
			let cachedTestAudioFile: File | null = null;

			// Function to clear the test audio cache (useful when switching audio files)
			function clearTestAudioCache() {
				cachedTestAudioFile = null;
				console.log('Test audio cache cleared');
			}

			// Function to initialize the live preview canvas
			function initializeLivePreview() {
				if (livePreviewCanvas && livePreviewContainer) {
					// Show the preview container
					livePreviewContainer.style.display = 'block';
					
					// Set canvas size for proper display
					const containerWidth = livePreviewContainer.clientWidth - 40; // Account for padding
					const aspectRatio = 16 / 9;
					const displayHeight = containerWidth / aspectRatio;
					
					livePreviewCanvas.style.width = `${containerWidth}px`;
					livePreviewCanvas.style.height = `${displayHeight}px`;
					
					// Clear the canvas
					const ctx = livePreviewCanvas.getContext('2d');
					if (ctx) {
						ctx.fillStyle = '#000';
						ctx.fillRect(0, 0, livePreviewCanvas.width, livePreviewCanvas.height);
					}
				}
			}

			// Browser-based video generation
			class BrowserVideoGenerator {
				private canvas: HTMLCanvasElement;
				private ctx: CanvasRenderingContext2D;
				private previewCanvas?: HTMLCanvasElement;
				private previewCtx?: CanvasRenderingContext2D;
				private audioContext: AudioContext | null = null;
				private audioData: Float32Array | null = null;
				private sampleRate: number = 44100;
				private seed: number;
				private timeOffset: number = 0; // For continuous evolution
				private generationId: number; // Unique ID for each generation
				private style: string; // Style preset

				// Memory-based motion system for truly organic movement
				private motionMemory: Map<number, { positions: number[], velocities: number[], lastTime: number }> = new Map();
				private globalTime: number = 0;

				constructor(previewCanvas?: HTMLCanvasElement, style: string = 'french-new-wave', seed?: number, generationId?: number) {
					this.canvas = document.createElement('canvas');
					this.canvas.width = 1920;
					this.canvas.height = 1080;
					this.ctx = this.canvas.getContext('2d')!;
					this.previewCanvas = previewCanvas;
					if (previewCanvas) {
						this.previewCtx = previewCanvas.getContext('2d')!;
					}
					this.seed = seed || Math.random() * 1000000;
					this.generationId = generationId || Math.floor(Math.random() * 1000000);
					this.style = style;
				}

				// Simple seeded random number generator
				private seededRandom(seed: number): () => number {
					let state = seed;
					return () => {
						state = (state * 9301 + 49297) % 233280;
						return state / 233280;
					};
				}

				// Get random value between min and max using seeded random
				private randomRange(seed: number, min: number, max: number): number {
					const random = this.seededRandom(seed);
					return min + (random() * (max - min));
				}

				// Get random integer between min and max using seeded random
				private randomInt(seed: number, min: number, max: number): number {
					return Math.floor(this.randomRange(seed, min, max + 1));
				}

				// Pick random element from array using seeded random
				private randomChoice<T>(seed: number, array: T[]): T {
					return array[this.randomInt(seed, 0, array.length - 1)];
				}

				// Get evolving parameter that changes over time with dramatic evolution
				private getEvolvingParam(baseValue: number, time: number, evolutionSpeed: number = 1, evolutionRange: number = 0.3): number {
					// Use multiple sine waves for more complex evolution
					const evolution1 = Math.sin(time * evolutionSpeed) * evolutionRange;
					const evolution2 = Math.sin(time * evolutionSpeed * 2.3) * evolutionRange * 0.5;
					const evolution3 = Math.sin(time * evolutionSpeed * 0.7) * evolutionRange * 0.3;
					return baseValue + evolution1 + evolution2 + evolution3;
				}

				// Get truly organic motion using memory and state evolution
				private getOrganicMotion(time: number, baseValue: number, amplitude: number, elementId: number, rms: number = 0.1): number {
					// Initialize memory for this element if it doesn't exist
					if (!this.motionMemory.has(elementId)) {
						this.motionMemory.set(elementId, {
							positions: [baseValue],
							velocities: [0],
							lastTime: time
						});
					}

					const memory = this.motionMemory.get(elementId)!;
					const timeDelta = time - memory.lastTime;
					
					// Get current state
					const currentPos = memory.positions[memory.positions.length - 1];
					const currentVel = memory.velocities[memory.velocities.length - 1];
					
					// Create organic forces based on history and environment
					const historyForce = this.getHistoryForce(memory, elementId);
					const environmentalForce = this.getEnvironmentalForce(time, elementId, baseValue);
					const randomForce = this.getRandomForce(time, elementId);
					const audioForce = this.getAudioForce(time, elementId, rms);
					
					// Combine forces with organic weighting
					const totalForce = historyForce * 0.3 + environmentalForce * 0.4 + randomForce * 0.2 + audioForce * 0.1;
					
					// Apply physics-like motion with damping
					const damping = 0.95;
					const newVel = currentVel * damping + totalForce * timeDelta;
					const newPos = currentPos + newVel * timeDelta;
					
					// Add some organic constraints
					const constrainedPos = this.applyOrganicConstraints(newPos, baseValue, amplitude, memory);
					
					// Update memory (keep last 10 positions for history)
					memory.positions.push(constrainedPos);
					memory.velocities.push(newVel);
					if (memory.positions.length > 10) {
						memory.positions.shift();
						memory.velocities.shift();
					}
					memory.lastTime = time;
					
					return constrainedPos;
				}

				// Get force based on movement history
				private getHistoryForce(memory: any, elementId: number): number {
					if (memory.positions.length < 3) return 0;
					
					// Calculate trend from recent history
					const recent = memory.positions.slice(-3);
					const trend = (recent[2] - recent[0]) / 2;
					
					// Add some organic "memory" - elements tend to continue recent patterns
					const momentum = trend * 0.5;
					
					// Add some "fatigue" - elements slow down over time
					const fatigue = -memory.velocities[memory.velocities.length - 1] * 0.1;
					
					// Add some "exploration" - elements occasionally change direction
					const exploration = Math.random() * 0.2 - 0.1;
					
					return momentum + fatigue + exploration;
				}

				// Get force from environment (other elements, boundaries, etc.)
				private getEnvironmentalForce(time: number, elementId: number, baseValue: number): number {
					// Create environmental "pressure" that changes over time
					const pressure = Math.sin(time * 0.1 + elementId * 0.3) * 0.5;
					
					// Add boundary attraction/repulsion
					const boundaryForce = this.getBoundaryForce(baseValue);
					
					// Add interaction with other elements (simplified)
					const interactionForce = this.getInteractionForce(elementId);
					
					return pressure + boundaryForce + interactionForce;
				}

				// Get boundary forces
				private getBoundaryForce(currentValue: number): number {
					const boundaryStrength = 0.3;
					const center = 0.5;
					const distance = currentValue - center;
					
					// Attract toward center when far away, repel when too close
					if (Math.abs(distance) > 0.3) {
						return -distance * boundaryStrength;
					} else if (Math.abs(distance) < 0.1) {
						return distance * boundaryStrength * 2;
					}
					return 0;
				}

				// Get interaction forces between elements
				private getInteractionForce(elementId: number): number {
					let totalForce = 0;
					
					// Simplified interaction with other elements
					this.motionMemory.forEach((memory, otherId) => {
						if (otherId !== elementId && memory.positions.length > 0) {
							const otherPos = memory.positions[memory.positions.length - 1];
							const distance = Math.abs(otherPos - 0.5);
							
							// Repel from other elements
							if (distance < 0.2) {
								totalForce += (0.5 - otherPos) * 0.1;
							}
						}
					});
					
					return totalForce;
				}

				// Get truly random force
				private getRandomForce(time: number, elementId: number): number {
					// Use time-based seed for reproducible randomness
					const seed = (time * 1000 + elementId * 100 + this.generationId) % 1000000;
					const random = (seed * 9301 + 49297) % 233280;
					return (random / 233280 - 0.5) * 0.3;
				}

				// Get force based on audio (RMS)
				private getAudioForce(time: number, elementId: number, rms: number): number {
					// This will be connected to the actual RMS value when available
					const simulatedRMS = Math.random() * 0.5;
					return simulatedRMS * 0.2;
				}

				// Apply organic constraints
				private applyOrganicConstraints(position: number, baseValue: number, amplitude: number, memory: any): number {
					// Soft boundaries
					const minBound = baseValue - amplitude;
					const maxBound = baseValue + amplitude;
					
					if (position < minBound) {
						position = minBound + (minBound - position) * 0.3; // Bounce with energy loss
					} else if (position > maxBound) {
						position = maxBound - (position - maxBound) * 0.3; // Bounce with energy loss
					}
					
					// Add some organic "stickiness" to recent positions
					if (memory.positions.length > 0) {
						const lastPos = memory.positions[memory.positions.length - 1];
						const stickiness = 0.1;
						position = position * (1 - stickiness) + lastPos * stickiness;
					}
					
					return position;
				}

				// Get evolving motion that changes behavior over time
				private getEvolvingMotion(time: number, baseValue: number, amplitude: number, elementId: number): number {
					// Create different motion phases that evolve over time
					const phase = Math.floor(time * 0.2 + elementId * 0.1) % 4;
					const phaseProgress = (time * 0.2 + elementId * 0.1) % 1;
					
					let motion = 0;
					
					switch (phase) {
						case 0: // Exploration phase
							motion = this.getExplorationMotion(time, elementId, amplitude);
							break;
						case 1: // Gathering phase
							motion = this.getGatheringMotion(time, elementId, amplitude);
							break;
						case 2: // Scattering phase
							motion = this.getScatteringMotion(time, elementId, amplitude);
							break;
						case 3: // Resting phase
							motion = this.getRestingMotion(time, elementId, amplitude);
							break;
					}
					
					// Add phase transition smoothing
					const transition = Math.sin(phaseProgress * Math.PI) * 0.5 + 0.5;
					
					return baseValue + motion * transition;
				}

				// Different motion behaviors
				private getExplorationMotion(time: number, elementId: number, amplitude: number): number {
					// Wide, slow exploration
					return Math.sin(time * 0.3 + elementId * 0.7) * amplitude * 0.8;
				}

				private getGatheringMotion(time: number, elementId: number, amplitude: number): number {
					// Move toward center
					const center = 0.5;
					return (center - 0.5) * amplitude * 0.6;
				}

				private getScatteringMotion(time: number, elementId: number, amplitude: number): number {
					// Move away from center
					const center = 0.5;
					return (0.5 - center) * amplitude * 0.6;
				}

				private getRestingMotion(time: number, elementId: number, amplitude: number): number {
					// Minimal movement
					return Math.sin(time * 0.1 + elementId * 0.3) * amplitude * 0.2;
				}

				// Get flocking-like motion
				private getFlockingMotion(time: number, baseValue: number, amplitude: number, elementId: number): number {
					// Simulate flocking behavior
					const alignment = this.getAlignmentForce(elementId);
					const cohesion = this.getCohesionForce(elementId);
					const separation = this.getSeparationForce(elementId);
					
					const flockingForce = alignment * 0.3 + cohesion * 0.3 + separation * 0.4;
					
					return baseValue + flockingForce * amplitude;
				}

				// Flocking forces
				private getAlignmentForce(elementId: number): number {
					let avgVelocity = 0;
					let count = 0;
					
					this.motionMemory.forEach((memory, otherId) => {
						if (otherId !== elementId && memory.velocities.length > 0) {
							avgVelocity += memory.velocities[memory.velocities.length - 1];
							count++;
						}
					});
					
					return count > 0 ? avgVelocity / count : 0;
				}

				private getCohesionForce(elementId: number): number {
					let avgPosition = 0;
					let count = 0;
					
					this.motionMemory.forEach((memory, otherId) => {
						if (otherId !== elementId && memory.positions.length > 0) {
							avgPosition += memory.positions[memory.positions.length - 1];
							count++;
						}
					});
					
					return count > 0 ? (avgPosition / count - 0.5) * 0.5 : 0;
				}

				private getSeparationForce(elementId: number): number {
					let separationForce = 0;
					
					this.motionMemory.forEach((memory, otherId) => {
						if (otherId !== elementId && memory.positions.length > 0) {
							const otherPos = memory.positions[memory.positions.length - 1];
							const distance = Math.abs(otherPos - 0.5);
							
							if (distance < 0.2) {
								separationForce += (0.5 - otherPos) * 0.3;
							}
						}
					});
					
					return separationForce;
				}

				// Get truly organic evolving motion with changing patterns
				private getOrganicEvolvingMotion(time: number, baseValue: number, amplitude: number, elementId: number): number {
					// Create multiple layers of motion that evolve independently
					const layer1 = Math.sin(time * 0.3 + elementId * 0.5) * amplitude * 0.4;
					const layer2 = Math.cos(time * 0.7 + elementId * 1.2) * amplitude * 0.3;
					const layer3 = Math.sin(time * 1.1 + elementId * 0.8) * amplitude * 0.2;
					
					// Add evolving direction changes
					const directionChange = Math.sin(time * 0.2 + elementId * 0.3) * Math.PI * 2;
					const evolvingMotion = Math.sin(time * 0.5 + directionChange) * amplitude * 0.3;
					
					// Add chaotic elements that change over time
					const chaos = Math.sin(time * 0.1 + elementId * 0.7) * Math.sin(time * 0.3 + elementId * 1.1) * amplitude * 0.2;
					
					return baseValue + layer1 + layer2 + layer3 + evolvingMotion + chaos;
				}

				// Get wandering motion that drifts in different directions over time
				private getWanderingMotion(time: number, baseValue: number, amplitude: number, wanderSpeed: number = 1): number {
					// Create wandering motion that changes direction periodically
					const wanderPhase = Math.floor(time * wanderSpeed * 0.2) * Math.PI * 2;
					const currentDirection = Math.sin(wanderPhase) * Math.PI * 2;
					
					// Add some randomness to the direction changes
					const randomOffset = this.seed * 0.1 + this.generationId * 0.05;
					const direction = currentDirection + randomOffset;
					
					// Create motion in the current direction
					const motion = Math.sin(time * wanderSpeed + direction) * amplitude;
					const drift = Math.cos(time * wanderSpeed * 0.3 + direction * 0.5) * amplitude * 0.4;
					
					return baseValue + motion + drift;
				}

				// Get flowing motion that follows natural curves
				private getFlowingMotion(time: number, baseValue: number, amplitude: number, flowSpeed: number = 1): number {
					// Create flowing motion that follows natural curves
					const flowPhase = time * flowSpeed;
					const curve1 = Math.sin(flowPhase) * amplitude;
					const curve2 = Math.sin(flowPhase * 2.3) * amplitude * 0.3;
					const curve3 = Math.cos(flowPhase * 0.7) * amplitude * 0.2;
					
					// Add gradual direction changes
					const directionShift = Math.sin(time * 0.1) * Math.PI * 0.5;
					const shiftedMotion = Math.sin(flowPhase + directionShift) * amplitude * 0.4;
					
					return baseValue + curve1 + curve2 + curve3 + shiftedMotion;
				}

				// Get complex organic motion with multiple evolving patterns
				private getComplexOrganicMotion(time: number, baseValue: number, amplitude: number, elementId: number): number {
					// Create a complex motion system with multiple evolving components
					
					// Primary motion with evolving frequency
					const primaryFreq = 0.3 + Math.sin(time * 0.1 + elementId * 0.2) * 0.2;
					const primaryMotion = Math.sin(time * primaryFreq + elementId * 0.5) * amplitude * 0.4;
					
					// Secondary motion with phase evolution
					const secondaryPhase = time * 0.2 + elementId * 1.3;
					const secondaryMotion = Math.cos(time * 0.7 + secondaryPhase) * amplitude * 0.3;
					
					// Tertiary motion with chaotic elements
					const chaos1 = Math.sin(time * 0.1 + elementId * 0.7) * Math.cos(time * 0.3 + elementId * 1.1);
					const chaos2 = Math.sin(time * 0.5 + elementId * 0.9) * Math.sin(time * 0.2 + elementId * 0.4);
					const chaoticMotion = (chaos1 + chaos2) * amplitude * 0.2;
					
					// Direction evolution
					const directionEvolution = Math.sin(time * 0.15 + elementId * 0.6) * Math.PI * 2;
					const evolvingMotion = Math.sin(time * 0.4 + directionEvolution) * amplitude * 0.3;
					
					// Pattern switching
					const patternSwitch = Math.sin(time * 0.08 + elementId * 0.3);
					const patternA = Math.sin(time * 0.6 + elementId * 0.8) * amplitude * 0.2;
					const patternB = Math.cos(time * 0.9 + elementId * 1.2) * amplitude * 0.2;
					const patternMotion = patternSwitch > 0 ? patternA : patternB;
					
					return baseValue + primaryMotion + secondaryMotion + chaoticMotion + evolvingMotion + patternMotion;
				}

				// Get morphing motion that transitions between different movement styles
				private getMorphingMotion(time: number, baseValue: number, amplitude: number, elementId: number): number {
					// Create motion that morphs between different movement patterns
					const morphPhase = (Math.sin(time * 0.1 + elementId * 0.4) + 1) / 2; // 0 to 1
					
					// Pattern A: Circular motion
					const patternA = Math.sin(time * 0.5 + elementId * 0.6) * amplitude * 0.4;
					
					// Pattern B: Linear motion with drift
					const patternB = Math.cos(time * 0.3 + elementId * 1.1) * amplitude * 0.3 + 
									Math.sin(time * 0.7 + elementId * 0.8) * amplitude * 0.2;
					
					// Pattern C: Chaotic motion
					const patternC = Math.sin(time * 0.2 + elementId * 0.9) * Math.cos(time * 0.4 + elementId * 1.3) * amplitude * 0.3;
					
					// Morph between patterns
					const motion = patternA * (1 - morphPhase) + patternB * morphPhase + patternC * Math.sin(time * 0.05);
					
					return baseValue + motion;
				}

				// Get evolving directional motion that changes over time
				private getEvolvingDirectionalMotion(time: number, baseValue: number, amplitude: number, evolutionSpeed: number = 1): number {
					// Use time-based direction changes to avoid looping patterns
					const directionPhase = Math.sin(time * evolutionSpeed * 0.3) * Math.PI * 2;
					const amplitudeModulation = Math.sin(time * evolutionSpeed * 0.7) * 0.5 + 0.5;
					
					// Create evolving motion with changing direction
					const motion1 = Math.sin(time * evolutionSpeed + directionPhase) * amplitude * amplitudeModulation;
					const motion2 = Math.cos(time * evolutionSpeed * 1.3 + directionPhase * 0.7) * amplitude * 0.6 * amplitudeModulation;
					const motion3 = Math.sin(time * evolutionSpeed * 0.5 + directionPhase * 1.4) * amplitude * 0.4 * amplitudeModulation;
					
					return baseValue + motion1 + motion2 + motion3;
				}

				// Get morphing parameter that transitions between different states
				private getMorphingParam(time: number, state1: number, state2: number, morphSpeed: number = 1): number {
					const morph = (Math.sin(time * morphSpeed) + 1) / 2; // 0 to 1
					return state1 + (state2 - state1) * morph;
				}

				// Update the preview canvas with the current frame
				private updatePreview(): void {
					if (this.previewCtx && this.previewCanvas) {
						// Clear the preview canvas
						this.previewCtx.clearRect(0, 0, this.previewCanvas.width, this.previewCanvas.height);
						
						// Scale the main canvas to fit the preview canvas
						const scaleX = this.previewCanvas.width / this.canvas.width;
						const scaleY = this.previewCanvas.height / this.canvas.height;
						const scale = Math.min(scaleX, scaleY);
						
						// Calculate centered position
						const scaledWidth = this.canvas.width * scale;
						const scaledHeight = this.canvas.height * scale;
						const x = (this.previewCanvas.width - scaledWidth) / 2;
						const y = (this.previewCanvas.height - scaledHeight) / 2;
						
						// Draw the main canvas onto the preview canvas
						this.previewCtx.drawImage(
							this.canvas,
							x, y,
							scaledWidth,
							scaledHeight
						);
					}
				}

				async analyzeAudio(audioFile: File): Promise<any> {
					console.log('Analyzing audio in browser...');
					
					try {
						// Create audio context
						this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
						
						// Resume audio context if suspended (required for autoplay policies)
						if (this.audioContext.state === 'suspended') {
							await this.audioContext.resume();
						}
						
						// Load audio file
						console.log('Loading audio file, size:', audioFile.size, 'type:', audioFile.type);
						const arrayBuffer = await audioFile.arrayBuffer();
						console.log('Audio file loaded as ArrayBuffer, size:', arrayBuffer.byteLength);
						
						const audioBuffer = await this.audioContext.decodeAudioData(arrayBuffer);
						console.log('Audio decoded successfully, duration:', audioBuffer.duration, 'sampleRate:', audioBuffer.sampleRate);
						
						// Extract audio data
						const channelData = audioBuffer.getChannelData(0);
						this.audioData = channelData;
						this.sampleRate = audioBuffer.sampleRate;
						
						// Calculate RMS values with more granular segments
						const fps = 30;
						const totalFrames = Math.floor(audioBuffer.duration * fps);
						const rmsValues = [];
						const vocalEnergy = [];
						const frequencies = [];
						
						// Create one RMS value per frame for better synchronization
						for (let frame = 0; frame < totalFrames; frame++) {
							const startTime = frame / fps;
							const endTime = (frame + 1) / fps;
							
							const startSample = Math.floor(startTime * this.sampleRate);
							const endSample = Math.floor(endTime * this.sampleRate);
							
							let sum = 0;
							let count = 0;
							
							for (let i = startSample; i < endSample && i < channelData.length; i++) {
								sum += channelData[i] * channelData[i];
								count++;
							}
							
							const rms = count > 0 ? Math.sqrt(sum / count) : 0.1;
							rmsValues.push(rms);
							vocalEnergy.push(Math.min(1, rms * 2));
							frequencies.push(150 + 100 * Math.sin(startTime * 2)); // Varying frequency
						}
						
						return {
							duration: audioBuffer.duration,
							rms: rmsValues,
							vocalEnergy: vocalEnergy,
							frequencies: frequencies,
							sampleRate: this.sampleRate,
							totalFrames: totalFrames
						};
					} catch (error) {
						console.error('Error in analyzeAudio:', error);
						
						// Provide more specific error messages
						if (error instanceof Error) {
							if (error.message.includes('decodeAudioData')) {
								throw new Error('Unable to decode audio data. The file may be corrupted or in an unsupported format.');
							} else if (error.message.includes('AudioContext')) {
								throw new Error('Audio context creation failed. Please check your browser audio settings.');
							} else {
								throw new Error(`Audio analysis failed: ${error.message}`);
							}
						} else {
							throw new Error('Unknown error during audio analysis');
						}
					}
				}

				generateFrame(time: number, rms: number): void {
					// Initialize global time for the first frame
					if (this.globalTime === 0) {
						this.globalTime = time;
					}
					
					// Clear motion memory when starting a new generation
					if (time < 0.1) {
						this.motionMemory.clear();
					}
					
					// Update global time
					this.globalTime = time;
					
					// Clear canvas
					this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);
					
					// Set background based on style
					if (this.style === 'french-new-wave') {
						this.ctx.fillStyle = '#000000';
						this.ctx.fillRect(0, 0, this.canvas.width, this.canvas.height);
					} else if (this.style === 'retro') {
						this.ctx.fillStyle = '#000000';
						this.ctx.fillRect(0, 0, this.canvas.width, this.canvas.height);
					} else if (this.style === 'wine-country') {
						this.ctx.fillStyle = '#2F4F2F';
						this.ctx.fillRect(0, 0, this.canvas.width, this.canvas.height);
					}
					
					// Generate elements based on style
					const seed = this.seed;
					
					if (this.style === 'french-new-wave') {
						this.generateFrenchNewWaveElements(time, rms, seed);
					} else if (this.style === 'retro') {
						this.generateRetroElements(time, rms, seed);
					} else if (this.style === 'wine-country') {
						this.generateWineCountryElements(time, rms, seed);
					}
					
					// Update the preview canvas
					this.updatePreview();
				}

				private generateFrenchNewWaveElements(time: number, rms: number, seed: number): void {
					// Jump cut effect with dramatic time evolution
					const threshold = this.getEvolvingParam(0.15, time, 0.6, 0.06);
					if (rms > threshold) {
						// Flash effect with evolving opacity and color
						const flashOpacity = this.getEvolvingParam(0.1, time, 1.2, 0.1);
						const flashColor = Math.sin(time * 0.8) > 0 ? 'rgba(255, 255, 255, ' : 'rgba(0, 0, 0, ';
						this.ctx.fillStyle = flashColor + flashOpacity + ')';
						this.ctx.fillRect(0, 0, this.canvas.width, this.canvas.height);
					}
					
					// Geometric shapes with memory-based organic motion
					const baseNumShapes = Math.floor(2 + rms * 4);
					const numShapes = this.randomInt(seed, baseNumShapes - 1, baseNumShapes + 3);
					
					for (let i = 0; i < numShapes; i++) {
						// Memory-based organic motion for positions
						const baseX = this.randomRange(seed + i * 100, this.canvas.width * 0.1, this.canvas.width * 0.9);
						const baseY = this.randomRange(seed + i * 200, this.canvas.height * 0.1, this.canvas.height * 0.9);
						
						// Use different motion types for variety
						const motionType = i % 3;
						let x, y;
						
						if (motionType === 0) {
							// Organic motion with memory
							x = this.getOrganicMotion(time, baseX, 80 + (rms * 150), i, rms);
							y = this.getOrganicMotion(time, baseY, 60 + (rms * 120), i + 100, rms);
						} else if (motionType === 1) {
							// Evolving motion with phases
							x = this.getEvolvingMotion(time, baseX, 70 + (rms * 130), i);
							y = this.getEvolvingMotion(time, baseY, 50 + (rms * 100), i + 100);
						} else {
							// Flocking motion
							x = this.getFlockingMotion(time, baseX, 90 + (rms * 160), i);
							y = this.getFlockingMotion(time, baseY, 65 + (rms * 110), i + 100);
						}
						
						// Dramatic evolving size and properties
						const baseSize = this.randomRange(seed + i * 300, 15, 25) + (rms * 60);
						const size = this.getEvolvingParam(baseSize, time, 0.8, baseSize * 0.5);
						const shapeThreshold = this.getEvolvingParam(0.2, time, 0.4, 0.08);
						
						// Authentic 1960s film look - only black, white, and grays
						const filmGrain = this.getFilmGrain(x, y, time, seed + i);
						const filmContrast = this.getFilmContrast(time, seed + i);
						
						if (rms > shapeThreshold) {
							// High contrast white with film grain
							const whiteValue = Math.max(220, 255 - filmGrain * 30); // Increased minimum brightness
							this.ctx.fillStyle = `rgb(${whiteValue}, ${whiteValue}, ${whiteValue})`;
							this.ctx.strokeStyle = '#000000';
						} else {
							// Brighter gray to black with film grain
							const grayValue = Math.max(20, Math.min(120, 60 - filmGrain * 20)); // Increased brightness range
							this.ctx.fillStyle = `rgb(${grayValue}, ${grayValue}, ${grayValue})`;
							this.ctx.strokeStyle = `rgb(${Math.max(0, grayValue - 20)}, ${Math.max(0, grayValue - 20)}, ${Math.max(0, grayValue - 20)})`;
						}
						
						// Film-like line width with variation
						const lineWidth = this.getEvolvingParam(1, time, 1.0, 1.0) + (rms * 2) + filmGrain * 2;
						this.ctx.lineWidth = Math.max(0.5, lineWidth);
						
						// Dramatic evolving shape types over time
						const shapeType = this.randomInt(seed + i * 600 + Math.floor(time * 3), 0, 4);
						
						if (shapeType === 0) {
							// Triangle with dramatic rotation and scaling
							const rotation = time * 1.2 + i;
							const scale = this.getEvolvingParam(1, time, 0.6, 0.5);
							this.ctx.save();
							this.ctx.translate(x, y);
							this.ctx.rotate(rotation);
							this.ctx.scale(scale, scale);
							this.ctx.beginPath();
							this.ctx.moveTo(0, -size);
							this.ctx.lineTo(-size, size);
							this.ctx.lineTo(size, size);
							this.ctx.closePath();
							this.ctx.fill();
							this.ctx.stroke();
							this.ctx.restore();
						} else if (shapeType === 1) {
							// Rectangle with dramatic scaling and rotation
							const scale = this.getEvolvingParam(1, time, 0.6, 0.6);
							const rotation = time * 0.8 + i * 0.5;
							this.ctx.save();
							this.ctx.translate(x, y);
							this.ctx.rotate(rotation);
							this.ctx.scale(scale, scale * this.getEvolvingParam(1, time, 0.4, 0.3));
							this.ctx.fillRect(-size, -size, size * 2, size * 2);
							this.ctx.strokeRect(-size, -size, size * 2, size * 2);
							this.ctx.restore();
						} else if (shapeType === 2) {
							// Circle with dramatic pulsing and morphing
							const pulse = this.getEvolvingParam(1, time, 1.2, 0.4);
							const morphX = this.getEvolvingParam(1, time, 0.8, 0.3);
							const morphY = this.getEvolvingParam(1, time, 0.6, 0.3);
							this.ctx.save();
							this.ctx.translate(x, y);
							this.ctx.scale(morphX, morphY);
							this.ctx.beginPath();
							this.ctx.arc(0, 0, size * pulse, 0, Math.PI * 2);
							this.ctx.fill();
							this.ctx.stroke();
							this.ctx.restore();
						} else if (shapeType === 3) {
							// Polygon with dramatic morphing
							const numPoints = this.randomInt(seed + i * 700, 5, 10);
							const morphFactor = this.getEvolvingParam(0.5, time, 0.8, 0.4);
							const rotation = time * 0.5;
							this.ctx.save();
							this.ctx.translate(x, y);
							this.ctx.rotate(rotation);
							this.ctx.beginPath();
							for (let j = 0; j < numPoints; j++) {
								const angle = (j * 2 * Math.PI) / numPoints;
								const radius = j % 2 === 0 ? size : size * morphFactor;
								const px = radius * Math.cos(angle + time * 0.4);
								const py = radius * Math.sin(angle + time * 0.4);
								if (j === 0) {
									this.ctx.moveTo(px, py);
								} else {
									this.ctx.lineTo(px, py);
								}
							}
							this.ctx.closePath();
							this.ctx.fill();
							this.ctx.stroke();
							this.ctx.restore();
						} else {
							// Star with dramatic morphing
							const numPoints = this.randomInt(seed + i * 800, 5, 8);
							const innerRadius = this.getEvolvingParam(size * 0.3, time, 0.6, size * 0.2);
							const outerRadius = this.getEvolvingParam(size, time, 0.4, size * 0.3);
							this.ctx.save();
							this.ctx.translate(x, y);
							this.ctx.rotate(time * 0.3);
							this.ctx.beginPath();
							for (let j = 0; j < numPoints * 2; j++) {
								const angle = (j * Math.PI) / numPoints;
								const radius = j % 2 === 0 ? outerRadius : innerRadius;
								const px = radius * Math.cos(angle);
								const py = radius * Math.sin(angle);
								if (j === 0) {
									this.ctx.moveTo(px, py);
								} else {
									this.ctx.lineTo(px, py);
								}
							}
							this.ctx.closePath();
							this.ctx.fill();
							this.ctx.stroke();
							this.ctx.restore();
						}
					}
					
					// Lines with memory-based organic motion
					const baseNumLines = Math.floor(2 + rms * 6);
					const numLines = this.randomInt(seed + 1000, baseNumLines - 1, baseNumLines + 3);
					
					for (let i = 0; i < numLines; i++) {
						const baseY = this.randomRange(seed + i * 200, this.canvas.height * 0.1, this.canvas.height * 0.9);
						const y1 = this.getOrganicMotion(time, baseY, 40, i + 200, rms);
						const y2 = y1 + this.getOrganicMotion(time, 0, 300, i + 300, rms);
						
						const strokeWidth = this.getEvolvingParam(1, time, 1.0, 1.0) + (rms * 5);
						const lineThreshold = this.getEvolvingParam(0.18, time, 0.4, 0.06);
						
						// Film grain for lines
						const lineGrain = this.getFilmGrain(0, baseY, time, seed + i + 1000);
						
						// Authentic film look for lines
						if (rms > lineThreshold) {
							const whiteValue = Math.max(200, 255 - lineGrain * 30); // Increased minimum brightness
							this.ctx.strokeStyle = `rgb(${whiteValue}, ${whiteValue}, ${whiteValue})`;
						} else {
							const grayValue = Math.max(10, Math.min(100, 50 - lineGrain * 15)); // Increased brightness range
							this.ctx.strokeStyle = `rgb(${grayValue}, ${grayValue}, ${grayValue})`;
						}
						
						this.ctx.lineWidth = strokeWidth + lineGrain * 1.5;
						this.ctx.beginPath();
						this.ctx.moveTo(0, y1);
						this.ctx.lineTo(this.canvas.width, y2);
						this.ctx.stroke();
					}
					
					// Add film grain overlay
					this.addFilmGrainOverlay(time, seed);
					
					// Add vignette effect
					this.addVignetteEffect();
					
					// Add film damage effects
					this.addFilmDamageEffects(time, seed);
				}

				// Generate authentic film grain
				private getFilmGrain(x: number, y: number, time: number, seed: number): number {
					// Simplified grain calculation for better performance and sync
					const grainX = Math.floor(x / 12); // Larger sampling for performance
					const grainY = Math.floor(y / 12);
					const grainTime = Math.floor(time * 3); // Reduced time sampling
					
					// Simplified pseudo-random calculation
					const grainSeed = (grainX * 73856093) ^ (grainY * 19349663) ^ (grainTime * 83492791) ^ seed;
					const grain = (grainSeed * 9301 + 49297) % 233280;
					
					return (grain / 233280) * 0.15; // Further reduced grain intensity
				}

				// Get film contrast variation
				private getFilmContrast(time: number, seed: number): number {
					const contrastSeed = (Math.floor(time * 5) * 73856093) ^ seed;
					const contrast = (contrastSeed * 9301 + 49297) % 233280;
					return (contrast / 233280) * 0.4 + 0.8; // Contrast between 0.8 and 1.2
				}

				// Add film grain overlay to the entire canvas
				private addFilmGrainOverlay(time: number, seed: number): void {
					// Only add grain overlay every 5 frames to maintain performance and sync
					if (Math.floor(time * 30) % 5 !== 0) return;
					
					const grainIntensity = 0.08; // Further reduced intensity
					const grainSize = 6; // Larger grain size for better performance
					
					// Sample even fewer pixels for better performance
					for (let x = 0; x < this.canvas.width; x += grainSize * 3) {
						for (let y = 0; y < this.canvas.height; y += grainSize * 3) {
							const grain = this.getFilmGrain(x, y, time, seed + x + y);
							
							if (grain > 0.85) {
								// Add white grain
								this.ctx.fillStyle = `rgba(255, 255, 255, ${grain * grainIntensity})`;
								this.ctx.fillRect(x, y, grainSize, grainSize);
							} else if (grain < 0.15) {
								// Add black grain
								this.ctx.fillStyle = `rgba(0, 0, 0, ${(0.15 - grain) * grainIntensity})`;
								this.ctx.fillRect(x, y, grainSize, grainSize);
							}
						}
					}
				}

				// Add vignette effect for authentic film look
				private addVignetteEffect(): void {
					const centerX = this.canvas.width / 2;
					const centerY = this.canvas.height / 2;
					const maxDistance = Math.sqrt(centerX * centerX + centerY * centerY);
					
					// Create radial gradient for vignette
					const gradient = this.ctx.createRadialGradient(
						centerX, centerY, 0,
						centerX, centerY, maxDistance * 0.8
					);
					
					gradient.addColorStop(0, 'rgba(0, 0, 0, 0)');
					gradient.addColorStop(0.8, 'rgba(0, 0, 0, 0)');
					gradient.addColorStop(1, 'rgba(0, 0, 0, 0.2)'); // Reduced from 0.4 to 0.2
					
					this.ctx.fillStyle = gradient;
					this.ctx.fillRect(0, 0, this.canvas.width, this.canvas.height);
				}

				// Add film damage effects like scratches and dust
				private addFilmDamageEffects(time: number, seed: number): void {
					// Only add damage effects every 8 frames to maintain performance and sync
					if (Math.floor(time * 30) % 8 !== 0) return;
					
					// Add horizontal scratches (reduced frequency)
					const numScratches = this.randomInt(seed + 2000, 0, 1); // Further reduced to 0-1
					for (let i = 0; i < numScratches; i++) {
						const scratchY = this.randomRange(seed + i * 300, 0, this.canvas.height);
						const scratchWidth = this.randomRange(seed + i * 400, 1, 2);
						const scratchOpacity = this.randomRange(seed + i * 500, 0.03, 0.1); // Further reduced opacity
						
						this.ctx.fillStyle = `rgba(255, 255, 255, ${scratchOpacity})`;
						this.ctx.fillRect(0, scratchY, this.canvas.width, scratchWidth);
					}
					
					// Add dust particles (reduced count)
					const numDust = this.randomInt(seed + 3000, 1, 3); // Further reduced to 1-3
					for (let i = 0; i < numDust; i++) {
						const dustX = this.randomRange(seed + i * 400, 0, this.canvas.width);
						const dustY = this.randomRange(seed + i * 500, 0, this.canvas.height);
						const dustSize = this.randomRange(seed + i * 600, 1, 2);
						const dustOpacity = this.randomRange(seed + i * 700, 0.05, 0.2); // Further reduced opacity
						
						this.ctx.fillStyle = `rgba(255, 255, 255, ${dustOpacity})`;
						this.ctx.beginPath();
						this.ctx.arc(dustX, dustY, dustSize, 0, Math.PI * 2);
						this.ctx.fill();
					}
					
					// Add film flicker (simplified and less frequent)
					const flicker = Math.sin(time * 10 + seed) * 0.03 + 0.97; // Reduced frequency and intensity
					this.ctx.globalAlpha = flicker;
					this.ctx.fillStyle = 'rgba(0, 0, 0, 0.01)'; // Further reduced opacity
					this.ctx.fillRect(0, 0, this.canvas.width, this.canvas.height);
					this.ctx.globalAlpha = 1.0;
				}

				private generateRetroElements(time: number, rms: number, seed: number): void {
					// Grid lines with memory-based organic spacing
					const baseGridSize = this.randomRange(seed, 40, 80) + (rms * 100);
					const gridSize = this.getEvolvingParam(baseGridSize, time, 0.4, baseGridSize * 0.5);
					const gridColor = this.randomChoice(seed, ['#ff00ff', '#00ffff', '#ffff00']);
					this.ctx.strokeStyle = gridColor;
					this.ctx.lineWidth = this.getEvolvingParam(1, time, 0.8, 1.0) + (rms * 2);
					
					// Memory-based organic animated grid
					for (let x = 0; x < this.canvas.width; x += gridSize) {
						const waveOffset = this.getOrganicMotion(time, 0, 20, x * 0.01, rms);
						this.ctx.beginPath();
						this.ctx.moveTo(x + waveOffset, 0);
						this.ctx.lineTo(x + waveOffset, this.canvas.height);
						this.ctx.stroke();
					}
					
					for (let y = 0; y < this.canvas.height; y += gridSize) {
						const waveOffset = this.getOrganicMotion(time, 0, 20, y * 0.01 + 1000, rms);
						this.ctx.beginPath();
						this.ctx.moveTo(0, y + waveOffset);
						this.ctx.lineTo(this.canvas.width, y + waveOffset);
						this.ctx.stroke();
					}
					
					// Circles with memory-based organic orbital motion
					const baseNumCircles = Math.floor(3 + rms * 5);
					const numCircles = this.randomInt(seed, baseNumCircles - 1, baseNumCircles + 3);
					
					for (let i = 0; i < numCircles; i++) {
						// Memory-based organic orbital motion around center
						const centerX = this.canvas.width / 2;
						const centerY = this.canvas.height / 2;
						const orbitRadius = this.randomRange(seed + i * 100, 100, 400);
						const orbitSpeed = this.randomRange(seed + i * 200, 0.5, 1.5);
						const orbitOffset = this.seed * (i + 1) + this.generationId;
						
						// Use memory-based organic motion for orbital paths
						const orbitX = this.getOrganicMotion(time, centerX, orbitRadius, i + 300, rms);
						const orbitY = this.getOrganicMotion(time, centerY, orbitRadius, i + 400, rms);
						
						const x = orbitX + this.getOrganicMotion(time, 0, orbitRadius * 0.3, i + 500, rms);
						const y = orbitY + this.getOrganicMotion(time, 0, orbitRadius * 0.3, i + 600, rms);
						
						const radius = this.getEvolvingParam(20, time, 1.2, 15) + (rms * 40);
						const hue = this.getEvolvingParam(i * 60, time, 0.4, 60);
						const saturation = this.getEvolvingParam(80, time, 0.6, 40);
						const brightness = this.getEvolvingParam(60, time, 0.5, 30);
						
						this.ctx.fillStyle = `hsl(${hue}, ${saturation}%, ${brightness}%)`;
						this.ctx.beginPath();
						this.ctx.arc(x, y, radius, 0, Math.PI * 2);
						this.ctx.fill();
					}
				}

				private generateWineCountryElements(time: number, rms: number, seed: number): void {
					// Vineyard-like elements with memory-based organic motion
					const baseNumVines = Math.floor(5 + rms * 10);
					const numVines = this.randomInt(seed, baseNumVines - 2, baseNumVines + 4);
					
					for (let i = 0; i < numVines; i++) {
						const x = this.randomRange(seed + i * 100, this.canvas.width * 0.05, this.canvas.width * 0.95);
						const startY = this.canvas.height * 0.8;
						const baseEndY = this.randomRange(seed + i * 200, this.canvas.height * 0.1, this.canvas.height * 0.4);
						
						// Dramatic growing effect over time
						const growthProgress = Math.min(1, time / 2); // Vines grow over first 2 seconds
						const endY = startY - (startY - baseEndY) * growthProgress;
						
						this.ctx.strokeStyle = this.randomChoice(seed + i * 300, ['#8B4513', '#A0522D', '#CD853F']);
						this.ctx.lineWidth = this.getEvolvingParam(2, time, 0.6, 2) + (rms * 3);
						this.ctx.beginPath();
						this.ctx.moveTo(x, startY);
						
						// Memory-based organic curved vine with natural motion
						for (let y = startY; y > endY; y -= 20) {
							const curveX = x + this.getOrganicMotion(time, 0, 50 + (rms * 50), i + y * 0.01, rms) + 
											this.getOrganicMotion(time, 0, 100, i + y * 0.02, rms);
							this.ctx.lineTo(curveX, y);
						}
						this.ctx.stroke();
						
						// Leaves with memory-based organic motion
						if (rms > 0.1 && growthProgress > 0.2) {
							const leafColor = this.randomChoice(seed + i * 600, ['#228B22', '#32CD32', '#90EE90']);
							this.ctx.fillStyle = leafColor;
							
							// Multiple leaves per vine with memory-based organic motion
							const numLeaves = this.randomInt(seed + i * 700, 1, 4);
							for (let l = 0; l < numLeaves; l++) {
								const leafY = endY + 50 + l * 40;
								const leafX = x + this.getOrganicMotion(time, 0, 40, i + l * 100, rms) * (l + 1);
								const leafSize = this.getEvolvingParam(10, time, 1.0, 8) + (rms * 25);
								const leafRotation = time * 0.4 + l * 0.5;
								
								this.ctx.save();
								this.ctx.translate(leafX, leafY);
								this.ctx.rotate(leafRotation);
								this.ctx.beginPath();
								this.ctx.ellipse(0, 0, leafSize, leafSize * 0.6, 0, 0, Math.PI * 2);
								this.ctx.fill();
								this.ctx.restore();
							}
						}
					}
					
					// Floating particles with memory-based organic motion
					if (rms > 0.12) {
						const numParticles = this.randomInt(seed + 2000, 5, 12);
						for (let p = 0; p < numParticles; p++) {
							const particleX = this.getOrganicMotion(time, this.canvas.width * 0.5, 300, p + 500, rms);
							const particleY = this.getOrganicMotion(time, this.canvas.height * 0.3, 150, p + 600, rms);
							const particleSize = this.getEvolvingParam(3, time, 1.2, 3) + (rms * 8);
							const particleOpacity = this.getEvolvingParam(0.3, time, 0.8, 0.2) + (rms * 0.4);
							
							this.ctx.fillStyle = `rgba(255, 255, 255, ${particleOpacity})`;
							this.ctx.beginPath();
							this.ctx.arc(particleX, particleY, particleSize, 0, Math.PI * 2);
							this.ctx.fill();
						}
					}
				}

				async generateVideo(audioAnalysis: any, stylePreset: string, onProgress?: (frame: number, total: number) => void, audioFile?: File): Promise<Blob> {
					console.log('Generating video in browser...');
					
					const fps = 30;
					const totalFrames = Math.floor(audioAnalysis.duration * fps);
					const chunks: Blob[] = [];
					
					// Create MediaRecorder with both video and audio
					const videoStream = this.canvas.captureStream(fps);
					
					// If we have an audio file, add it to the stream
					if (audioFile && this.audioContext && this.audioContext.state === 'running') {
						try {
							// Create audio element and load the audio file
							const audioElement = document.createElement('audio');
							audioElement.src = URL.createObjectURL(audioFile);
							audioElement.crossOrigin = 'anonymous';
							
							// Create audio context and connect audio element
							const audioDestination = this.audioContext.createMediaStreamDestination();
							const audioSource = this.audioContext.createMediaElementSource(audioElement);
							audioSource.connect(audioDestination);
							audioSource.connect(this.audioContext.destination); // Also connect to speakers for monitoring
							
							// Combine video and audio streams
							const combinedStream = new MediaStream([
								...videoStream.getVideoTracks(),
								...audioDestination.stream.getAudioTracks()
							]);
							
							const mediaRecorder = new MediaRecorder(combinedStream, {
								mimeType: 'video/webm;codecs=vp9,opus'
							});
							
							return new Promise((resolve, reject) => {
								mediaRecorder.ondataavailable = (event) => {
									if (event.data.size > 0) {
										chunks.push(event.data);
									}
								};
								
								mediaRecorder.onstop = () => {
									const blob = new Blob(chunks, { type: 'video/webm' });
									resolve(blob);
								};
								
								mediaRecorder.onerror = reject;
								
								// Start recording and playing audio
								mediaRecorder.start();
								audioElement.play();
								
								// Generate frames
								let frameIndex = 0;
								const frameInterval = 1000 / fps;
								
								const generateNextFrame = () => {
									if (frameIndex >= totalFrames) {
										mediaRecorder.stop();
										audioElement.pause();
										return;
									}
									
									const time = frameIndex / fps;
									this.generateFrame(time, audioAnalysis.rms[frameIndex] || 0.1);
									
									if (onProgress) {
										onProgress(frameIndex + 1, totalFrames);
									}
									
									frameIndex++;
									setTimeout(generateNextFrame, frameInterval);
								};
								
								generateNextFrame();
							});
						} catch (error) {
							console.warn('Failed to add audio to video, generating video-only:', error);
							// Fall back to video-only if audio fails
						}
					}
					
					// Fallback: video-only recording
					const mediaRecorder = new MediaRecorder(videoStream, {
						mimeType: 'video/webm;codecs=vp9'
					});
					
					return new Promise((resolve, reject) => {
						mediaRecorder.ondataavailable = (event) => {
							if (event.data.size > 0) {
								chunks.push(event.data);
							}
						};
						
						mediaRecorder.onstop = () => {
							const blob = new Blob(chunks, { type: 'video/webm' });
							resolve(blob);
						};
						
						mediaRecorder.onerror = reject;
						
						// Start recording
						mediaRecorder.start();
						
						// Generate frames
						let frameIndex = 0;
						const frameInterval = 1000 / fps;
						
						const generateNextFrame = () => {
							if (frameIndex >= totalFrames) {
								mediaRecorder.stop();
								return;
							}
							
							const time = frameIndex / fps;
							this.generateFrame(time, audioAnalysis.rms[frameIndex] || 0.1);
							
							if (onProgress) {
								onProgress(frameIndex + 1, totalFrames);
							}
							
							frameIndex++;
							setTimeout(generateNextFrame, frameInterval);
						};
						
						generateNextFrame();
					});
				}

				async addOverlays(videoBlob: Blob, title: string, guest: string, sponsor: string): Promise<Blob> {
					console.log('Adding overlays in browser...');
					
					// For now, return the original blob
					// In a full implementation, you would use Canvas to add text overlays
					// This is a simplified version
					return videoBlob;
				}

				generateTestAudio(duration: number = 10): Float32Array {
					console.log('Generating test audio...');
					
					const sampleRate = 44100;
					const numSamples = Math.floor(duration * sampleRate);
					const audioData = new Float32Array(numSamples);
					
					// Generate a simple sine wave with varying frequency and amplitude
					for (let i = 0; i < numSamples; i++) {
						const time = i / sampleRate;
						const frequency = 200 + 100 * Math.sin(time * 0.5); // Varying frequency
						const amplitude = 0.3 + 0.2 * Math.sin(time * 2); // Varying amplitude
						const wave = Math.sin(2 * Math.PI * frequency * time);
						
						// Add some variation for more interesting RMS patterns
						const variation = Math.sin(time * 10) * 0.1;
						audioData[i] = (wave + variation) * amplitude;
					}
					
					return audioData;
				}

				createTestAudioAnalysis(duration: number = 10): any {
					console.log('Creating test audio analysis...');
					
					const rmsValues = [];
					const vocalEnergy = [];
					const frequencies = [];
					
					// Generate 100 segments of varying RMS values
					for (let i = 0; i < 100; i++) {
						const time = (i / 100) * duration;
						const baseRms = 0.1 + 0.2 * Math.sin(time * 2) + 0.1 * Math.sin(time * 5);
						const rms = Math.max(0.05, Math.min(0.8, baseRms));
						
						rmsValues.push(rms);
						vocalEnergy.push(Math.min(1, rms * 2));
						frequencies.push(150 + 100 * Math.sin(time * 3));
					}
					
					return {
						duration: duration,
						rms: rmsValues,
						vocalEnergy: vocalEnergy,
						frequencies: frequencies,
						sampleRate: 44100
					};
				}

				// Get truly non-looping chaotic motion using state evolution
				private getChaoticMotion(time: number, baseValue: number, amplitude: number, elementId: number): number {
					// Use a chaotic system that never repeats
					const state1 = (time * 0.3 + elementId * 0.7 + this.generationId * 0.1) % 1;
					const state2 = (time * 0.7 + elementId * 1.3 + this.generationId * 0.2) % 1;
					const state3 = (time * 1.1 + elementId * 0.9 + this.generationId * 0.3) % 1;
					
					// Chaotic mapping using logistic map-like behavior
					const chaos1 = state1 * (1 - state1) * 4;
					const chaos2 = state2 * (1 - state2) * 4;
					const chaos3 = state3 * (1 - state3) * 4;
					
					// Combine chaotic states with evolving weights
					const weight1 = (time * 0.1 + elementId * 0.3) % 1;
					const weight2 = (time * 0.2 + elementId * 0.5) % 1;
					const weight3 = (time * 0.3 + elementId * 0.7) % 1;
					
					const motion = (chaos1 * weight1 + chaos2 * weight2 + chaos3 * weight3) / (weight1 + weight2 + weight3);
					
					return baseValue + (motion - 0.5) * amplitude * 2;
				}

				// Get evolving state-based motion that changes behavior over time
				private getStateBasedMotion(time: number, baseValue: number, amplitude: number, elementId: number): number {
					// Create evolving states that change behavior
					const statePhase = Math.floor(time * 0.5 + elementId * 0.2) % 4;
					const stateProgress = (time * 0.5 + elementId * 0.2) % 1;
					
					let motion = 0;
					
					switch (statePhase) {
						case 0: // Linear drift
							motion = stateProgress * amplitude;
							break;
						case 1: // Exponential growth
							motion = Math.pow(stateProgress, 2) * amplitude;
							break;
						case 2: // Logarithmic decay
							motion = Math.log(stateProgress + 0.1) * amplitude * 0.5;
							break;
						case 3: // Random walk
							const randomWalk = (time * 0.3 + elementId * 0.7) % 1;
							motion = (randomWalk - 0.5) * amplitude;
							break;
					}
					
					// Add chaotic perturbation
					const perturbation = ((time * 0.1 + elementId * 0.3) % 1) * amplitude * 0.3;
					
					return baseValue + motion + perturbation;
				}

				// Get fractal-based motion using recursive patterns
				private getFractalMotion(time: number, baseValue: number, amplitude: number, elementId: number): number {
					// Use fractal-like patterns that never repeat exactly
					const fractal1 = this.getFractalValue(time * 0.3, elementId * 0.5, 3);
					const fractal2 = this.getFractalValue(time * 0.7, elementId * 1.2, 4);
					const fractal3 = this.getFractalValue(time * 1.1, elementId * 0.8, 5);
					
					// Combine fractals with evolving weights
					const weight1 = (time * 0.05 + elementId * 0.1) % 1;
					const weight2 = (time * 0.08 + elementId * 0.2) % 1;
					const weight3 = (time * 0.12 + elementId * 0.3) % 1;
					
					const motion = (fractal1 * weight1 + fractal2 * weight2 + fractal3 * weight3) / (weight1 + weight2 + weight3);
					
					return baseValue + motion * amplitude;
				}

				// Helper function for fractal calculations
				private getFractalValue(input: number, seed: number, depth: number): number {
					if (depth <= 0) return 0;
					
					const scaled = input * Math.pow(2, depth);
					const fract = scaled - Math.floor(scaled);
					const noise = (seed * fract * 1000) % 1;
					
					return noise + this.getFractalValue(input, seed * 1.5, depth - 1) * 0.5;
				}

				// Get cellular automaton-like motion
				private getCellularMotion(time: number, baseValue: number, amplitude: number, elementId: number): number {
					// Simulate cellular automaton behavior
					const cell1 = Math.floor(time * 0.2 + elementId * 0.3) % 256;
					const cell2 = Math.floor(time * 0.4 + elementId * 0.7) % 256;
					const cell3 = Math.floor(time * 0.6 + elementId * 1.1) % 256;
					
					// Cellular automaton rule (simplified)
					const rule = (cell1 + cell2 + cell3) % 256;
					const evolution = (rule * time * 0.1 + elementId * 0.5) % 1;
					
					// Add neighborhood effects
					const neighbor1 = Math.sin(time * 0.3 + elementId * 0.2) * 0.3;
					const neighbor2 = Math.cos(time * 0.5 + elementId * 0.4) * 0.3;
					
					const motion = (evolution + neighbor1 + neighbor2) / 3;
					
					return baseValue + (motion - 0.5) * amplitude * 2;
				}

				// Get particle system motion with collision-like behavior
				private getParticleMotion(time: number, baseValue: number, amplitude: number, elementId: number): number {
					// Simulate particle physics with evolving parameters
					const velocity = (time * 0.2 + elementId * 0.3) % 1;
					const acceleration = (time * 0.1 + elementId * 0.5) % 1;
					const friction = 0.95 + (elementId * 0.01) % 0.1;
					
					// Particle position with physics simulation
					let position = velocity * time + 0.5 * acceleration * time * time;
					position = position % 1; // Wrap around
					
					// Add collision-like behavior
					const collision = Math.floor(time * 0.5 + elementId * 0.7) % 2;
					if (collision === 1) {
						position = 1 - position; // Bounce
					}
					
					// Add noise for unpredictability
					const noise = ((time * 0.3 + elementId * 0.9) % 1) * 0.2;
					
					return baseValue + (position - 0.5 + noise) * amplitude * 2;
				}

				// Get neural network-like motion with evolving weights
				private getNeuralMotion(time: number, baseValue: number, amplitude: number, elementId: number): number {
					// Simulate neural network with evolving weights
					const input1 = (time * 0.2 + elementId * 0.3) % 1;
					const input2 = (time * 0.4 + elementId * 0.7) % 1;
					const input3 = (time * 0.6 + elementId * 1.1) % 1;
					
					// Evolving weights
					const weight1 = (time * 0.1 + elementId * 0.2) % 1;
					const weight2 = (time * 0.15 + elementId * 0.4) % 1;
					const weight3 = (time * 0.2 + elementId * 0.6) % 1;
					
					// Neural activation
					const activation = Math.tanh(input1 * weight1 + input2 * weight2 + input3 * weight3);
					
					// Add evolving bias
					const bias = (time * 0.05 + elementId * 0.1) % 1;
					
					return baseValue + (activation + bias) * amplitude * 0.5;
				}

				// Get genetic algorithm-like motion with mutation
				private getGeneticMotion(time: number, baseValue: number, amplitude: number, elementId: number): number {
					// Simulate genetic algorithm with mutation and crossover
					const gene1 = (time * 0.3 + elementId * 0.5) % 1;
					const gene2 = (time * 0.7 + elementId * 1.2) % 1;
					const gene3 = (time * 1.1 + elementId * 0.8) % 1;
					
					// Crossover operation
					const crossover = (gene1 + gene2) / 2;
					
					// Mutation rate that evolves over time
					const mutationRate = (time * 0.1 + elementId * 0.2) % 0.3;
					const mutation = ((time * 0.2 + elementId * 0.4) % 1) * mutationRate;
					
					// Fitness-based selection
					const fitness = Math.abs(gene3 - 0.5);
					const selection = fitness > 0.3 ? gene3 : crossover;
					
					// Final motion with mutation
					const motion = selection + mutation;
					
					return baseValue + (motion - 0.5) * amplitude * 2;
				}
			}

			// File validation
			fileInput.addEventListener('change', (e) => {
				const file = (e.target as HTMLInputElement).files?.[0];
				if (file) {
					const sizeMB = (file.size / (1024 * 1024)).toFixed(2);
					fileInfo.textContent = `File: ${file.name} (${sizeMB} MB)`;
					
					if (file.size > 250 * 1024 * 1024) {
						fileInfo.style.color = '#ef4444';
						fileInfo.textContent += ' - File too large (max 250MB)';
					} else {
						fileInfo.style.color = '#10b981';
					}
				}
			});

			// Generate consistent parameters for video generation
			function generateVideoParams() {
				const seed = Math.random() * 1000000;
				const generationId = Math.floor(Math.random() * 1000000);
				return { seed, generationId };
			}

			// Form submit handler
			form.addEventListener('submit', async (event) => {
				event.preventDefault();
				
				const fileInput = document.getElementById('audioFile') as HTMLInputElement;
				const file = fileInput.files?.[0];
				
				if (!file) {
					alert('Please select an audio file.');
					return;
				}
				
				// Show status
				status.style.display = 'block';
				results.style.display = 'none';
				progressBar.style.width = '0%';
				statusText.textContent = 'Starting video generation...';
				statusText.style.color = '#10b981';
				frameCountIndicator.textContent = '';

				// Initialize live preview
				initializeLivePreview();

				try {
					// Get form data
					const title = (document.getElementById('title') as HTMLInputElement).value || 'Untitled';
					const guest = (document.getElementById('guest') as HTMLInputElement).value || '';
					const sponsor = (document.getElementById('sponsor') as HTMLInputElement).value || '';
					const stylePreset = (document.getElementById('stylePreset') as HTMLSelectElement).value;
					
					// Generate consistent parameters
					const { seed, generationId } = generateVideoParams();
					
					// Convert style preset to internal style name
					let internalStyle = 'french-new-wave';
					if (stylePreset === 'French New Wave') {
						internalStyle = 'french-new-wave';
					} else if (stylePreset === "'80s Retro Chromatic") {
						internalStyle = 'retro';
					} else if (stylePreset === 'Wine-Country Dreamscape') {
						internalStyle = 'wine-country';
					}
					
					// Create browser video generator with consistent parameters
					const videoGenerator = new BrowserVideoGenerator(livePreviewCanvas, internalStyle, seed, generationId);
					
					// Analyze audio
					statusText.textContent = 'Analyzing audio...';
					const audioAnalysis = await videoGenerator.analyzeAudio(file);
					console.log('Audio analysis complete:', audioAnalysis);
					
					// Generate video
					statusText.textContent = 'Generating video frames...';
					stageIndicator.textContent = 'Stage 1: Frame Generation';
					
					const videoBlob = await videoGenerator.generateVideo(audioAnalysis, stylePreset, (frame, total) => {
						const percentage = (frame / total) * 100;
						progressBar.style.width = `${percentage}%`;
						const progressText = progressBar.querySelector('div');
						if (progressText) progressText.textContent = `${Math.round(percentage)}%`;
						frameCountIndicator.textContent = `Frames: ${frame} / ${total}`;
					}, file);
					
					// Add overlays
					statusText.textContent = 'Adding overlays...';
					stageIndicator.textContent = 'Stage 2: Adding Overlays';
					const finalVideoBlob = await videoGenerator.addOverlays(videoBlob, title, guest, sponsor);
					
					// Create download link
					currentVideoUrl = URL.createObjectURL(finalVideoBlob);
					currentVideoPath = 'browser-generated-video.webm';
					
					// Show results
					statusText.textContent = 'Video generation complete!';
					stageIndicator.textContent = 'Complete!';
					statusText.style.color = '#10b981';
					progressBar.style.width = '100%';
					const progressText = progressBar.querySelector('div');
					if (progressText) progressText.textContent = '100%';
					
					showResults({
						duration: audioAnalysis.duration,
						videoPath: currentVideoPath
					});
					
				} catch (error) {
					console.log('Error in form submit handler:', error);
					statusText.textContent = `Error: ${error instanceof Error ? error.message : String(error)}`;
					statusText.style.color = '#ef4444';
					frameCountIndicator.textContent = 'Please check your file and try again';
				}
			});

			function showResults(result: any) {
				const title = (document.getElementById('title') as HTMLInputElement).value || 'Untitled Episode';
				const duration = Math.floor(result.duration || (Math.random() * 60) + 30);
				
				videoInfo.innerHTML = `
					<h4>${title}</h4>
					<p>Duration: ${Math.floor(duration / 60)}:${(duration % 60).toString().padStart(2, '0')}</p>
					<p>Resolution: 1920x1080 (1080p)</p>
					<p>Format: WebM (Browser Generated)</p>
				`;
				
				// Set video source
				if (currentVideoUrl) {
					// Show loading indicator
					videoLoadingIndicator.style.display = 'block';
					videoPlayer.style.display = 'none';
					
					videoPlayer.src = currentVideoUrl;
					videoPlayer.load(); // Load the video
					
					// Add event listener for when video is loaded
					videoPlayer.addEventListener('loadedmetadata', () => {
						console.log('Video loaded successfully');
						// Hide loading indicator and show video
						videoLoadingIndicator.style.display = 'none';
						videoPlayer.style.display = 'block';
					});
					
					videoPlayer.addEventListener('error', (e) => {
						console.error('Error loading video:', e);
						// Hide loading indicator on error
						videoLoadingIndicator.style.display = 'none';
						videoPlayer.style.display = 'block';
					});
				}
				
				results.style.display = 'block';
			}

			// Download button
			downloadBtn.addEventListener('click', () => {
				if (currentVideoUrl) {
					const a = document.createElement('a');
					a.href = currentVideoUrl;
					a.download = 'video-wallpaper.webm';
					document.body.appendChild(a);
					a.click();
					document.body.removeChild(a);
				} else {
					alert('No video available for download.');
				}
			});

			// YouTube upload button
			youtubeBtn.addEventListener('click', async () => {
				alert('YouTube upload requires server-side processing. Please use the server version for YouTube integration.');
			});

			// Test video buttons
			testVideoFrenchNewWave.addEventListener('click', async () => {
				console.log('Test video button clicked');
				
				// Disable button during generation
				testVideoFrenchNewWave.disabled = true;
				testVideoFrenchNewWave.textContent = 'ðŸŽ¬ Generating...';
				
				// Show status
				status.style.display = 'block';
				results.style.display = 'none';
				progressBar.style.width = '0%';
				statusText.textContent = 'Generating test video...';
				statusText.style.color = '#10b981';
				frameCountIndicator.textContent = '';

				// Initialize live preview
				initializeLivePreview();

				try {
					// Clear cache to ensure we use the latest audio file
					clearTestAudioCache();
					
					// Generate consistent parameters
					const { seed, generationId } = generateVideoParams();
					
					// Create browser video generator with consistent parameters
					const videoGenerator = new BrowserVideoGenerator(livePreviewCanvas, 'french-new-wave', seed, generationId);
					
					// Get or create the pre-built test audio file
					statusText.textContent = cachedTestAudioFile ? 'Using cached test audio...' : 'Loading test audio file...';
					const testAudioFile = await getTestAudioFile();
					
					// Analyze the test audio file to create audio context and get proper analysis
					statusText.textContent = 'Analyzing test audio...';
					const audioAnalysis = await videoGenerator.analyzeAudio(testAudioFile);
					console.log('Test audio analysis complete:', audioAnalysis);
					
					// Pre-configured settings
					const title = 'Test Video - Browser Generated';
					const guest = 'Demo Guest';
					const sponsor = 'Demo Sponsor';
					const stylePreset = 'French New Wave'; // Default to French New Wave for testing
					
					// Generate video
					statusText.textContent = 'Generating test video frames...';
					stageIndicator.textContent = 'Stage 1: Frame Generation';
					
					const videoBlob = await videoGenerator.generateVideo(audioAnalysis, stylePreset, (frame, total) => {
						const percentage = (frame / total) * 100;
						progressBar.style.width = `${percentage}%`;
						const progressText = progressBar.querySelector('div');
						if (progressText) progressText.textContent = `${Math.round(percentage)}%`;
						frameCountIndicator.textContent = `Frames: ${frame} / ${total}`;
					}, testAudioFile);
					
					// Add overlays
					statusText.textContent = 'Adding test overlays...';
					stageIndicator.textContent = 'Stage 2: Adding Overlays';
					const finalVideoBlob = await videoGenerator.addOverlays(videoBlob, title, guest, sponsor);
					
					// Create download link
					currentVideoUrl = URL.createObjectURL(finalVideoBlob);
					currentVideoPath = 'test-video-browser-generated.webm';
					
					// Show results
					statusText.textContent = 'Test video generation complete!';
					stageIndicator.textContent = 'Complete!';
					statusText.style.color = '#10b981';
					progressBar.style.width = '100%';
					const progressText = progressBar.querySelector('div');
					if (progressText) progressText.textContent = '100%';
					
					showResults({
						duration: audioAnalysis.duration,
						videoPath: currentVideoPath
					});
					
					console.log('âœ… Test video generated successfully');
					
				} catch (error) {
					console.log('Error generating test video:', error);
					statusText.textContent = `Error: ${error instanceof Error ? error.message : String(error)}`;
					statusText.style.color = '#ef4444';
					frameCountIndicator.textContent = 'Test video generation failed';
				} finally {
					// Re-enable button
					testVideoFrenchNewWave.disabled = false;
					testVideoFrenchNewWave.textContent = 'ðŸŽ¬ French New Wave';
				}
			});

			testVideoRetro.addEventListener('click', async () => {
				console.log('Test video button clicked');
				
				// Disable button during generation
				testVideoRetro.disabled = true;
				testVideoRetro.textContent = 'ðŸŽ¬ Generating...';
				
				// Show status
				status.style.display = 'block';
				results.style.display = 'none';
				progressBar.style.width = '0%';
				statusText.textContent = 'Generating test video...';
				statusText.style.color = '#10b981';
				frameCountIndicator.textContent = '';

				// Initialize live preview
				initializeLivePreview();

				try {
					// Clear cache to ensure we use the latest audio file
					clearTestAudioCache();
					
					// Generate consistent parameters
					const { seed, generationId } = generateVideoParams();
					
					// Create browser video generator with consistent parameters
					const videoGenerator = new BrowserVideoGenerator(livePreviewCanvas, 'retro', seed, generationId);
					
					// Get or create the pre-built test audio file
					statusText.textContent = cachedTestAudioFile ? 'Using cached test audio...' : 'Loading test audio file...';
					const testAudioFile = await getTestAudioFile();
					
					// Analyze the test audio file to create audio context and get proper analysis
					statusText.textContent = 'Analyzing test audio...';
					const audioAnalysis = await videoGenerator.analyzeAudio(testAudioFile);
					console.log('Test audio analysis complete:', audioAnalysis);
					
					// Pre-configured settings
					const title = 'Test Video - Browser Generated';
					const guest = 'Demo Guest';
					const sponsor = 'Demo Sponsor';
					const stylePreset = "'80s Retro Chromatic"; // Use exact style preset name
					
					// Generate video
					statusText.textContent = 'Generating test video frames...';
					stageIndicator.textContent = 'Stage 1: Frame Generation';
					
					const videoBlob = await videoGenerator.generateVideo(audioAnalysis, stylePreset, (frame, total) => {
						const percentage = (frame / total) * 100;
						progressBar.style.width = `${percentage}%`;
						const progressText = progressBar.querySelector('div');
						if (progressText) progressText.textContent = `${Math.round(percentage)}%`;
						frameCountIndicator.textContent = `Frames: ${frame} / ${total}`;
					}, testAudioFile);
					
					// Add overlays
					statusText.textContent = 'Adding test overlays...';
					stageIndicator.textContent = 'Stage 2: Adding Overlays';
					const finalVideoBlob = await videoGenerator.addOverlays(videoBlob, title, guest, sponsor);
					
					// Create download link
					currentVideoUrl = URL.createObjectURL(finalVideoBlob);
					currentVideoPath = 'test-video-browser-generated.webm';
					
					// Show results
					statusText.textContent = 'Test video generation complete!';
					stageIndicator.textContent = 'Complete!';
					statusText.style.color = '#10b981';
					progressBar.style.width = '100%';
					const progressText = progressBar.querySelector('div');
					if (progressText) progressText.textContent = '100%';
					
					showResults({
						duration: audioAnalysis.duration,
						videoPath: currentVideoPath
					});
					
					console.log('âœ… Test video generated successfully');
					
				} catch (error) {
					console.log('Error generating test video:', error);
					statusText.textContent = `Error: ${error instanceof Error ? error.message : String(error)}`;
					statusText.style.color = '#ef4444';
					frameCountIndicator.textContent = 'Test video generation failed';
				} finally {
					// Re-enable button
					testVideoRetro.disabled = false;
					testVideoRetro.textContent = 'ðŸŽ¬ 80s Retro Chromatic';
				}
			});

			testVideoWineCountry.addEventListener('click', async () => {
				console.log('Test video button clicked');
				
				// Disable button during generation
				testVideoWineCountry.disabled = true;
				testVideoWineCountry.textContent = 'ðŸŽ¬ Generating...';
				
				// Show status
				status.style.display = 'block';
				results.style.display = 'none';
				progressBar.style.width = '0%';
				statusText.textContent = 'Generating test video...';
				statusText.style.color = '#10b981';
				frameCountIndicator.textContent = '';

				// Initialize live preview
				initializeLivePreview();

				try {
					// Clear cache to ensure we use the latest audio file
					clearTestAudioCache();
					
					// Generate consistent parameters
					const { seed, generationId } = generateVideoParams();
					
					// Create browser video generator with consistent parameters
					const videoGenerator = new BrowserVideoGenerator(livePreviewCanvas, 'wine-country', seed, generationId);
					
					// Get or create the pre-built test audio file
					statusText.textContent = cachedTestAudioFile ? 'Using cached test audio...' : 'Loading test audio file...';
					const testAudioFile = await getTestAudioFile();
					
					// Analyze the test audio file to create audio context and get proper analysis
					statusText.textContent = 'Analyzing test audio...';
					const audioAnalysis = await videoGenerator.analyzeAudio(testAudioFile);
					console.log('Test audio analysis complete:', audioAnalysis);
					
					// Pre-configured settings
					const title = 'Test Video - Browser Generated';
					const guest = 'Demo Guest';
					const sponsor = 'Demo Sponsor';
					const stylePreset = 'Wine-Country Dreamscape'; // Default to Wine-Country Dreamscape for testing
					
					// Generate video
					statusText.textContent = 'Generating test video frames...';
					stageIndicator.textContent = 'Stage 1: Frame Generation';
					
					const videoBlob = await videoGenerator.generateVideo(audioAnalysis, stylePreset, (frame, total) => {
						const percentage = (frame / total) * 100;
						progressBar.style.width = `${percentage}%`;
						const progressText = progressBar.querySelector('div');
						if (progressText) progressText.textContent = `${Math.round(percentage)}%`;
						frameCountIndicator.textContent = `Frames: ${frame} / ${total}`;
					}, testAudioFile);
					
					// Add overlays
					statusText.textContent = 'Adding test overlays...';
					stageIndicator.textContent = 'Stage 2: Adding Overlays';
					const finalVideoBlob = await videoGenerator.addOverlays(videoBlob, title, guest, sponsor);
					
					// Create download link
					currentVideoUrl = URL.createObjectURL(finalVideoBlob);
					currentVideoPath = 'test-video-browser-generated.webm';
					
					// Show results
					statusText.textContent = 'Test video generation complete!';
					stageIndicator.textContent = 'Complete!';
					statusText.style.color = '#10b981';
					progressBar.style.width = '100%';
					const progressText = progressBar.querySelector('div');
					if (progressText) progressText.textContent = '100%';
					
					showResults({
						duration: audioAnalysis.duration,
						videoPath: currentVideoPath
					});
					
					console.log('âœ… Test video generated successfully');
					
				} catch (error) {
					console.log('Error generating test video:', error);
					statusText.textContent = `Error: ${error instanceof Error ? error.message : String(error)}`;
					statusText.style.color = '#ef4444';
					frameCountIndicator.textContent = 'Test video generation failed';
				} finally {
					// Re-enable button
					testVideoWineCountry.disabled = false;
					testVideoWineCountry.textContent = 'ðŸŽ¬ Wine-Country Dreamscape';
				}
			});

			// Utility function to get the pre-built test audio file
			async function getTestAudioFile(): Promise<File> {
				if (cachedTestAudioFile) {
					return cachedTestAudioFile;
				}

				console.log('Loading pre-built test audio file...');
				
				try {
					// Try multiple possible paths for the audio file
					const possiblePaths = [
						'/test-audio-5sec.mp3',
						'./test-audio-5sec.mp3',
						'test-audio-5sec.mp3'
					];
					
					let response: Response | null = null;
					let audioBlob: Blob | null = null;
					
					for (const path of possiblePaths) {
						try {
							console.log(`Trying to fetch audio file from: ${path}`);
							response = await fetch(path);
							console.log(`Response status for ${path}:`, response.status);
							
							if (response.ok) {
								audioBlob = await response.blob();
								console.log(`Successfully loaded audio file from ${path}, size:`, audioBlob.size);
								
								// Check if we actually got an audio file
								if (audioBlob.type.includes('audio') || audioBlob.type.includes('mp3') || audioBlob.size > 1000) {
									break;
								} else {
									console.warn(`Got non-audio response from ${path}, type:`, audioBlob.type, 'size:', audioBlob.size);
									audioBlob = null;
									continue;
								}
							}
						} catch (pathError) {
							console.warn(`Failed to fetch from ${path}:`, pathError);
							continue;
						}
					}
					
					// If we couldn't load the external file, generate one programmatically
					if (!audioBlob) {
						console.log('External audio file not available, generating synthetic audio...');
						audioBlob = await generateSyntheticAudio();
					}
					
					// Verify the blob is actually an audio file
					if (audioBlob.size === 0) {
						throw new Error('Audio file is empty');
					}
					
					cachedTestAudioFile = new File([audioBlob], 'test-audio-5sec.mp3', { type: 'audio/mp3' });
					console.log('Test audio file loaded and cached successfully');
					
					return cachedTestAudioFile;
				} catch (error) {
					console.error('Error loading test audio file:', error);
					
					// Provide more specific error messages
					if (error instanceof TypeError && error.message.includes('fetch')) {
						throw new Error('Network error loading audio file. Please check your connection.');
					} else if (error instanceof Error && error.message.includes('404')) {
						throw new Error('Audio file not found. Please contact support.');
					} else {
						throw new Error(`Failed to load test audio file: ${error instanceof Error ? error.message : String(error)}`);
					}
				}
			}

			// Fallback function to generate synthetic audio
			async function generateSyntheticAudio(): Promise<Blob> {
				console.log('Generating synthetic audio file...');
				
				const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
				if (audioContext.state === 'suspended') {
					await audioContext.resume();
				}
				
				// Generate a simple melody-like audio
				const sampleRate = audioContext.sampleRate;
				const duration = 5; // 5 seconds
				const numSamples = Math.floor(duration * sampleRate);
				const audioBuffer = audioContext.createBuffer(1, numSamples, sampleRate);
				const channelData = audioBuffer.getChannelData(0);
				
				// Generate a simple melody with varying frequency and amplitude
				for (let i = 0; i < numSamples; i++) {
					const time = i / sampleRate;
					const frequency = 200 + 100 * Math.sin(time * 0.5) + 50 * Math.sin(time * 2);
					const amplitude = 0.3 + 0.2 * Math.sin(time * 1.5);
					const wave = Math.sin(2 * Math.PI * frequency * time);
					
					// Add some harmonics for more interesting sound
					const harmonic1 = 0.3 * Math.sin(2 * Math.PI * frequency * 2 * time);
					const harmonic2 = 0.1 * Math.sin(2 * Math.PI * frequency * 3 * time);
					
					channelData[i] = (wave + harmonic1 + harmonic2) * amplitude;
				}
				
				// Convert AudioBuffer to Blob
				const audioBlob = await new Promise<Blob>((resolve) => {
					const mediaStreamDestination = audioContext.createMediaStreamDestination();
					const source = audioContext.createBufferSource();
					source.buffer = audioBuffer;
					source.connect(mediaStreamDestination);
					
					const mediaRecorder = new MediaRecorder(mediaStreamDestination.stream);
					const chunks: Blob[] = [];
					
					mediaRecorder.ondataavailable = (event) => {
						if (event.data.size > 0) {
							chunks.push(event.data);
						}
					};
					
					mediaRecorder.onstop = () => {
						const blob = new Blob(chunks, { type: 'audio/webm' });
						resolve(blob);
					};
					
					mediaRecorder.start();
					source.start();
					
					setTimeout(() => {
						mediaRecorder.stop();
					}, 5500); // Slightly longer than 5 seconds to ensure complete capture
				});
				
				console.log('Synthetic audio generated successfully, size:', audioBlob.size);
				return audioBlob;
			}
		</script>
	</body>
</html>
